import streamlit as st
import os
import yaml
import logging
import pandas as pd
import plotly.graph_objects as go
from pathlib import Path

logger = logging.getLogger(__name__)
BASE_PATH = Path(__file__).parent.parent.parent

def show():
    """Display the analyzer page content."""
    st.title("AI Ethics Analysis")
    
    # Model and scenario selection
    col1, col2 = st.columns(2)
    with col1:
        selected_model = st.selectbox(
            "Select AI Model",
            ["Gradient Boost", "Random Forest", "Neural Network", "XGBoost"],
            key='selected_model'
        )
    
    with col2:
        selected_scenario = st.selectbox(
            "Select Scenario",
            ["Loan Default", "Candidate Selection", "Fraud Detection", "Credit Scoring"],
            key='selected_scenario'
        )

    # Enable AEPF analysis option
    enable_aepf = st.checkbox("Include AEPF Analysis", value=True)

    if st.button("Run Analysis"):
        try:
            # Create columns for side-by-side display
            model_col, aepf_col = st.columns(2)
            
            with model_col:
                st.markdown("### AI Model Analysis")
                model_results = generate_sample_model_results()
                show_model_summary(model_results)
            
            if enable_aepf:
                with aepf_col:
                    st.markdown("### AEPF Analysis")
                    aepf_report = generate_sample_aepf_report()
                    display_aepf_summary(aepf_report)
                
        except Exception as e:
            st.error(f"Error during analysis: {str(e)}")
            logger.error("Analysis error", exc_info=True)

def show_model_summary(report: dict):
    """Display AI model summary metrics."""
    try:
        st.markdown("### Model Performance Analysis")
        
        # Add trend analysis visualization
        trend_data = pd.DataFrame({
            'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],
            'Accuracy': [0.82, 0.84, 0.85, 0.86, 0.85, 0.87],
            'Recall': [0.80, 0.82, 0.85, 0.84, 0.86, 0.87]
        })
        
        fig_trend = go.Figure()
        fig_trend.add_trace(go.Scatter(x=trend_data['Month'], y=trend_data['Accuracy'], 
                                     name='Accuracy', mode='lines+markers'))
        fig_trend.add_trace(go.Scatter(x=trend_data['Month'], y=trend_data['Recall'], 
                                     name='Recall', mode='lines+markers'))
        fig_trend.update_layout(title='Performance Trends Over Time')
        st.plotly_chart(fig_trend, use_container_width=True)
        
        st.markdown("""
            ### ðŸ“Š Performance Overview
            This comprehensive analysis shows strong model performance with:
            - Consistent accuracy improvement over 6 months
            - Balanced precision and recall metrics
            - Robust cross-validation results
            
            ### ðŸŽ¯ Key Achievements
            - 40% faster processing speed
            - 96% decision consistency
            - 25% reduction in false positives
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            accuracy = report['technical_analysis'].get('accuracy', 0)
            st.metric("Model Accuracy", f"{accuracy:.2%}")
            st.markdown(f"""
                *{'Strong' if accuracy > 0.8 else 'Moderate'} prediction reliability*
                
                The model demonstrates {'excellent' if accuracy > 0.85 else 'good'} 
                performance in its primary task, with consistent results across different scenarios.
            """)
            
            approval = report['loan_analysis'].get('approval_rate', 0)
            st.metric("Approval Rate", f"{approval:.1%}")
            st.markdown("*Rate of positive decisions across all applications*")
            
        with col2:
            recall = report['technical_analysis'].get('recall', 0)
            st.metric("Default Detection", f"{recall:.2%}")
            st.markdown("*Ability to identify relevant cases requiring attention*")
            
            rates = report['loan_analysis'].get('interest_rates', {})
            avg_rate = rates.get('mean', 0)
            st.metric("Average Interest", f"{avg_rate:.1%}")
            st.markdown("*Mean rate applied across approved applications*")

        # Risk Distribution Analysis
        st.markdown("### Risk Profile Distribution")
        st.markdown("#### Geographic Risk Distribution")
        geo_data = pd.DataFrame({
            'Region': ['North', 'South', 'East', 'West', 'Central'],
            'Risk Score': [0.82, 0.78, 0.85, 0.80, 0.83]
        })
        fig_geo = go.Figure(data=[go.Bar(x=geo_data['Region'], y=geo_data['Risk Score'])])
        fig_geo.update_layout(title='Risk Scores by Region')
        st.plotly_chart(fig_geo, use_container_width=True)
        
        st.markdown("### Risk Profile Distribution")
        risk_dist = report['risk_assessment']['distribution']
        fig = go.Figure(data=[go.Pie(labels=list(risk_dist.keys()),
                                    values=list(risk_dist.values()),
                                    hole=.3)])
        st.plotly_chart(fig, use_container_width=True)

        # Add PDF download button
        st.markdown("---")
        st.download_button(
            "ðŸ“¥ Download Full Model Report (PDF)",
            data=b"Sample PDF content",  # Replace with actual PDF generation
            file_name="model_analysis_report.pdf",
            mime="application/pdf"
        )
            
    except Exception as e:
        st.error(f"Error displaying model summary: {str(e)}")
        logger.error("Model summary error", exc_info=True)

def display_aepf_summary(report: dict):
    """Display AEPF analysis summary."""
    try:
        if not report:
            st.error("No AEPF analysis data available")
            return
            
        # Overall ethical score with gold stars
        overall_score = report.get('overall_score', 0.75)
        stars = f'<span style="color: gold">{"â˜…" * int(overall_score * 5)}</span>' + \
                f'<span style="color: gray">{"â˜†" * (5 - int(overall_score * 5))}</span>'
        st.markdown(f"### Ethical Assessment Rating: {stars}", unsafe_allow_html=True)
        
        # Add fairness comparison chart
        fairness_data = pd.DataFrame({
            'Category': ['Gender', 'Age', 'Location', 'Income', 'Education'],
            'Score': [0.95, 0.92, 0.88, 0.90, 0.93],
            'Benchmark': [0.85, 0.85, 0.85, 0.85, 0.85]
        })
        
        fig_fair = go.Figure()
        fig_fair.add_trace(go.Bar(x=fairness_data['Category'], y=fairness_data['Score'], 
                                name='Current Score'))
        fig_fair.add_trace(go.Bar(x=fairness_data['Category'], y=fairness_data['Benchmark'], 
                                name='Industry Benchmark'))
        fig_fair.update_layout(title='Fairness Metrics vs Industry Benchmarks')
        st.plotly_chart(fig_fair, use_container_width=True)
        
        st.markdown("""
            ### ðŸŽ¯ Key Ethical Metrics
            
            Our comprehensive assessment reveals:
            
            **Fairness Excellence:**
            - Above industry benchmarks
            - Strong demographic balance
            - Minimal outcome variation (<3%)
            
            **Transparency Leadership:**
            - Clear decision explanations
            - Accessible documentation
            - Regular stakeholder updates
        """)
        
        # Key metrics in columns
        col1, col2 = st.columns(2)
        with col1:
            fairness = report.get('fairness_score', 0)
            st.metric("Fairness Score", f"{fairness:.1%}")
            st.markdown("""
                *Measures the model's ability to make unbiased decisions
                across different demographic groups*
            """)
            
        with col2:
            transparency = report.get('transparency_score', 0)
            st.metric("Transparency", f"{transparency:.1%}")
            st.markdown("""
                *Evaluates how well the model's decisions can be
                explained and understood*
            """)
            
        # Impact assessment with context
        st.markdown("### Societal Impact Analysis")
        st.markdown("""
            This section evaluates the broader implications of the model's deployment
            across different societal dimensions:
        """)
        impact = report.get('impact_assessment', {})
        for category, score in impact.items():
            st.metric(f"{category}", f"{score:.1%}")
            if category == 'Individual':
                st.markdown("*Impact on individual rights and autonomy*")
            elif category == 'Community':
                st.markdown("*Effects on community cohesion and equality*")
            elif category == 'Systemic':
                st.markdown("*Long-term institutional and structural implications*")

        # Add PDF download button
        st.markdown("---")
        st.download_button(
            "ðŸ“¥ Download Full AEPF Report (PDF)",
            data=b"Sample PDF content",  # Replace with actual PDF generation
            file_name="ethical_analysis_report.pdf",
            mime="application/pdf"
        )
            
    except Exception as e:
        st.error(f"Error displaying AEPF summary: {str(e)}")
        logger.error("AEPF summary error", exc_info=True)

def generate_sample_model_results():
    """Generate sample model results for demonstration."""
    return {
        'technical_analysis': {
            'accuracy': 0.85,
            'precision': 0.83,
            'recall': 0.87,
            'f1_score': 0.85
        },
        'loan_analysis': {
            'approval_rate': 0.72,
            'interest_rates': {
                'mean': 0.045,
                'median': 0.042,
                'std': 0.008
            }
        },
        'risk_assessment': {
            'distribution': {
                'Low Risk': 45,
                'Medium Risk': 35,
                'High Risk': 15,
                'Very High Risk': 5
            }
        }
    }

def generate_sample_aepf_report():
    """Generate sample AEPF analysis results."""
    return {
        'overall_score': 0.78,
        'risk_level': 'Low',
        'fairness_score': 0.82,
        'transparency_score': 0.75,
        'impact_assessment': {
            'Individual': 0.82,
            'Community': 0.76,
            'Systemic': 0.73
        },
        'recommendations': [
            'Enhance model documentation',
            'Implement regular fairness audits',
            'Develop appeals process'
        ]
    }
